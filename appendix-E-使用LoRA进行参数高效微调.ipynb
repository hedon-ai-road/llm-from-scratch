{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d5cd83",
   "metadata": {},
   "source": [
    "### 1. 准备数据集\n",
    "\n",
    "1. 下载和准备数据集\n",
    "2. 实例化 PyTorch 数据集\n",
    "3. 创建 PyTorch 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a435a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from download_classify_data import (\n",
    "    download_and_unzip_spam_data,\n",
    "    create_balanced_dataset,\n",
    "    random_split,\n",
    "    url, zip_path, extracted_path, data_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c76f82",
   "metadata": {},
   "source": [
    "#### 1.1 下载和准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6738dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "df = pd.read_csv(\n",
    "    data_file_path, sep=\"\\t\", header=None, names = [\"Label\", \"Text\"]\n",
    ")\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477616c7",
   "metadata": {},
   "source": [
    "#### 1.2 实例化 PyTorch 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bf0ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken\n",
    "\n",
    "class SapmDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        \n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long),\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = SapmDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "val_dataset = SapmDataset(\"validation.csv\", max_length=None, tokenizer=tokenizer)\n",
    "test_dataset = SapmDataset(\"test.csv\", max_length=None, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d16651",
   "metadata": {},
   "source": [
    "#### 1.3 创建 Python 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d112bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader( \n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader( \n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = DataLoader( \n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b9abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimension: torch.Size([8, 120])\n",
      "Target batch dimension: torch.Size([8])\n",
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimension:\", input_batch.shape)\n",
    "print(\"Target batch dimension:\", target_batch.shape)\n",
    "\n",
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fbe6c7",
   "metadata": {},
   "source": [
    "### 2. 初始化模型\n",
    "\n",
    "1. 加载预训练的 GPT 模型\n",
    "2. 准备分类微调模型：替换输出层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805fcb89",
   "metadata": {},
   "source": [
    "#### 2.1 加载预训练的 GPT 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c37e5ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from gpt_model import GPTModel\n",
    "from load_gpt2 import load_weights_into_gpt\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f401a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from gpt_model import generate_text_simple, text_to_token_ids, token_ids_to_text\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_length=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f84a9",
   "metadata": {},
   "source": [
    "#### 2.2 替换输出层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76e0e637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "202ab47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 53.75%\n",
      "Test accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "from calc import calc_accuracy_loader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af599e6",
   "metadata": {},
   "source": [
    "### 3. 使用 LoRA 进行高效微调\n",
    "\n",
    "1. 实现 LoRA 层\n",
    "2. 用 LinearWithLoRA 层替换 Linear 层\n",
    "3. 冻结原始模型的参数\n",
    "4. 使用 LoRA 层微调模型\n",
    "\n",
    "<img src=\"https://hedonspace.oss-cn-beijing.aliyuncs.com/img/image-20250822094136223.png\" alt=\"用 LinearWithLoRA 层替换 Linear 层\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24983a3",
   "metadata": {},
   "source": [
    "#### 3.1 实现 LoRA 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cea722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    \"\"\"LoRA 层\"\"\"\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha) -> None:\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "549bc069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear: torch.nn.Linear, rank, alpha) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f25cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model: GPTModel, rank, alpha):\n",
    "    \"\"\"将模型中所有现有的 Linear 层替换为新创建的 LinearWithLoRA 层\"\"\"\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f8fa7",
   "metadata": {},
   "source": [
    "#### 3.4 冻结原始模型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f296509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "total_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_param:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "total_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_param:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "464e58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "total_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_param:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff3ba8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_key): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (W_value): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (out_proj): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): LinearWithLoRA(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): LinearWithLoRA(\n",
       "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       "    (lora): LoRALayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d5286",
   "metadata": {},
   "source": [
    "#### 3.3 使用 LoRA 微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bc1472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 53.75%\n",
      "Test accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a34628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calc import calc_loss_batch, calc_loss_loader\n",
    "\n",
    "def train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # 重置上一次批次迭代的损失梯度\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fba207b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.832, Val loss 1.914\n",
      "Ep 1 (Step 000050): Train loss 0.276, Val loss 0.276\n",
      "Ep 1 (Step 000100): Train loss 0.060, Val loss 0.183\n",
      "Training accuracy: 87.50% | Validation accuracy: 100.00%\n",
      "Ep 2 (Step 000150): Train loss 0.067, Val loss 0.218\n",
      "Ep 2 (Step 000200): Train loss 0.115, Val loss 0.140\n",
      "Ep 2 (Step 000250): Train loss 0.045, Val loss 0.033\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 3 (Step 000300): Train loss 0.049, Val loss 0.014\n",
      "Ep 3 (Step 000350): Train loss 0.020, Val loss 0.021\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 4 (Step 000400): Train loss 0.024, Val loss 0.003\n",
      "Ep 4 (Step 000450): Train loss 0.003, Val loss 0.154\n",
      "Ep 4 (Step 000500): Train loss 0.000, Val loss 0.027\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.001, Val loss 0.085\n",
      "Ep 5 (Step 000600): Train loss 0.000, Val loss 0.010\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Training completed in 1.43 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = \\\n",
    "    train_classifier_simple(\n",
    "        model, train_loader, val_loader, optimizer, device,\n",
    "        num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    "    )\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6ac600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "example_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_losses(\n",
    "    epochs_tensor, example_seen_tensor,\n",
    "    train_losses, val_losses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5946a45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.00%\n",
      "Validation accuracy: 98.75%\n",
      "Test accuracy: 96.25%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
