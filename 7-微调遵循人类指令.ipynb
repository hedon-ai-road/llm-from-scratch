{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076f2a87",
   "metadata": {},
   "source": [
    "### 1. 定义提示词格式函数\n",
    "\n",
    "两种提示词风格：\n",
    "\n",
    "1. Alpaca\n",
    "    - 使用 \"###\" 作为分隔符\n",
    "    - 使用 \"### Instruction:\" 作为指令\n",
    "    - 使用 \"### Response:\" 作为响应\n",
    "    - 使用 \"### Input:\" 作为输入\n",
    "    - 使用 \"### Output:\" 作为输出\n",
    "\n",
    "2. Phi-3\n",
    "    - <|user|> 作为用户输入的开始\n",
    "    - <|assistant|> 作为模型输出的开始\n",
    "    - <|endoftext|> 作为结束\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ff943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describe a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3519fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n",
      "Example entry: \n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n",
      "Below is an instruction that describe a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion \n",
      "\n",
      "Below is an instruction that describe a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n"
     ]
    }
   ],
   "source": [
    "from download_instruction_data import download_and_load_file, url, file_path\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "\n",
    "print(format_input(data[50]), \"\\n\")\n",
    "print(format_input(data[999]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2c8c74",
   "metadata": {},
   "source": [
    "### 2. 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4771db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion: train_portion + test_portion]\n",
    "val_data = data[train_portion+test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf24773",
   "metadata": {},
   "source": [
    "### 3. 将数据组织成训练批次\n",
    "\n",
    "1. 使用提示词模版制作格式化数据\n",
    "2. 将格式化数据词元化\n",
    "3. 用填充词元调整到同一长度（批内相同）\n",
    "4. 创建目标词元 ID 用于训练（左移一位）\n",
    "5. 用占位符 -100 替换填充词元（忽略这部分的损失计算）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd5b40",
   "metadata": {},
   "source": [
    "#### 3.1/3.2 使用提示词模版制作格式化数据 & 将格式化数据词元化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8883cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ed257",
   "metadata": {},
   "source": [
    "#### 3.3 用填充词元调整到同一长度（批内相同）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9752c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd675567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3,\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136fba6",
   "metadata": {},
   "source": [
    "#### 3.4 创建目标词元 ID 用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03177f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:]) # 左移一个位置得到目标\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f57fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ab3644",
   "metadata": {},
   "source": [
    "#### 3.5 用占位符 -100 替换部分填充词元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a2cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70a0d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251e15c",
   "metadata": {},
   "source": [
    "### 4. 创建指令数据集的数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "945905b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1334f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a75fbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f34e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1876600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.InstructionDataset'>\n",
      "<class 'type'>\n",
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(InstructionDataset)\n",
    "print(type(InstructionDataset))\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e7ad7",
   "metadata": {},
   "source": [
    "### 5. 加载预训练的大语言模型\n",
    "\n",
    "使用 3.55 亿的中等规模 GPT 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79a6abcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n",
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from gpt_model import GPTModel\n",
    "from load_gpt2 import load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True,\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a908999c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      " Below is an instruction that describe a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "\n",
      "===========\n",
      "Response:\n",
      " ### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(\"Input text:\\n\", input_text)\n",
    "\n",
    "\n",
    "from gpt_model import generate, token_ids_to_text, text_to_token_ids\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_length=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(\"\\n\\n===========\\nResponse:\\n\", response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f3a53",
   "metadata": {},
   "source": [
    "### 6. 在指令数据上微调大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eea4968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.904631185531616\n",
      "Validation loss: 3.842133808135986\n"
     ]
    }
   ],
   "source": [
    "from train import  calc_loss_loader, train_model_simple\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ca25b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000):Train loss 4.034, Val loss 4.448\n",
      "Ep 1 (Step 000005):Train loss 3.096, Val loss 3.181\n",
      "Ep 1 (Step 000010):Train loss 2.074, Val loss 2.353\n",
      "Ep 1 (Step 000015):Train loss 1.592, Val loss 1.781\n",
      "Ep 1 (Step 000020):Train loss 1.246, Val loss 1.466\n",
      "Ep 1 (Step 000025):Train loss 1.106, Val loss 1.277\n",
      "Ep 1 (Step 000030):Train loss 1.181, Val loss 1.228\n",
      "Ep 1 (Step 000035):Train loss 1.016, Val loss 1.163\n",
      "Ep 1 (Step 000040):Train loss 0.973, Val loss 1.116\n",
      "Ep 1 (Step 000045):Train loss 0.940, Val loss 1.078\n",
      "Ep 1 (Step 000050):Train loss 1.022, Val loss 1.045\n",
      "Ep 1 (Step 000055):Train loss 1.050, Val loss 1.020\n",
      "Ep 1 (Step 000060):Train loss 0.982, Val loss 0.994\n",
      "Ep 1 (Step 000065):Train loss 0.895, Val loss 0.976\n",
      "Ep 1 (Step 000070):Train loss 0.819, Val loss 0.959\n",
      "Ep 1 (Step 000075):Train loss 0.806, Val loss 0.946\n",
      "Ep 1 (Step 000080):Train loss 0.881, Val loss 0.938\n",
      "Ep 1 (Step 000085):Train loss 0.776, Val loss 0.931\n",
      "Ep 1 (Step 000090):Train loss 0.880, Val loss 0.921\n",
      "Ep 1 (Step 000095):Train loss 0.797, Val loss 0.913\n",
      "Ep 1 (Step 000100):Train loss 0.753, Val loss 0.916\n",
      "Ep 1 (Step 000105):Train loss 0.866, Val loss 0.910\n",
      "Ep 1 (Step 000110):Train loss 0.881, Val loss 0.907\n",
      "Ep 1 (Step 000115):Train loss 0.820, Val loss 0.903\n",
      "Below is an instruction that describe a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The The The The The The The  The  The   The            \n",
      "Ep 2 (Step 000120):Train loss 0.769, Val loss 0.899\n",
      "Ep 2 (Step 000125):Train loss 0.798, Val loss 0.892\n",
      "Ep 2 (Step 000130):Train loss 0.789, Val loss 0.888\n",
      "Ep 2 (Step 000135):Train loss 0.731, Val loss 0.880\n",
      "Ep 2 (Step 000140):Train loss 0.762, Val loss 0.875\n",
      "Ep 2 (Step 000145):Train loss 0.688, Val loss 0.867\n",
      "Ep 2 (Step 000150):Train loss 0.665, Val loss 0.859\n",
      "Ep 2 (Step 000155):Train loss 0.724, Val loss 0.853\n",
      "Ep 2 (Step 000160):Train loss 0.766, Val loss 0.845\n",
      "Ep 2 (Step 000165):Train loss 0.728, Val loss 0.841\n",
      "Ep 2 (Step 000170):Train loss 0.636, Val loss 0.834\n",
      "Ep 2 (Step 000175):Train loss 0.634, Val loss 0.832\n",
      "Ep 2 (Step 000180):Train loss 0.714, Val loss 0.825\n",
      "Ep 2 (Step 000185):Train loss 0.740, Val loss 0.821\n",
      "Ep 2 (Step 000190):Train loss 0.613, Val loss 0.820\n",
      "Ep 2 (Step 000195):Train loss 0.686, Val loss 0.812\n",
      "Ep 2 (Step 000200):Train loss 0.580, Val loss 0.811\n",
      "Ep 2 (Step 000205):Train loss 0.674, Val loss 0.805\n",
      "Ep 2 (Step 000210):Train loss 0.715, Val loss 0.802\n",
      "Ep 2 (Step 000215):Train loss 0.733, Val loss 0.798\n",
      "Ep 2 (Step 000220):Train loss 0.618, Val loss 0.799\n",
      "Ep 2 (Step 000225):Train loss 0.688, Val loss 0.797\n",
      "Ep 2 (Step 000230):Train loss 0.596, Val loss 0.793\n",
      "Training completed in 2.49 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=1e-5, weight_decay=0.1,\n",
    ")\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47592a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035b218",
   "metadata": {},
   "source": [
    "### 7. 提取并保存模型回复"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653643c",
   "metadata": {},
   "source": [
    "#### 7.1 打印测试集前 3 个看看效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4521cab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describe a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is very fast.\n",
      "-------------------------------------\n",
      "Below is an instruction that describe a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is typically a thunderstorm with a high wind speed.\n",
      "-------------------------------------\n",
      "Below is an instruction that describe a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Sir Thomas More.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_length=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256,\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    \n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce480e9",
   "metadata": {},
   "source": [
    "#### 7.2 生成完整测试集上的回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6992cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [03:36<00:00,  1.97s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_length=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256,\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33e3fba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'instruction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Rewrite the sentence using a simile.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The car is very fast.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'output'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The car is as fast as lightning.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_response'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The car is very fast.'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'instruction'\u001b[0m: \u001b[32m'Rewrite the sentence using a simile.'\u001b[0m,\n",
       "    \u001b[32m'input'\u001b[0m: \u001b[32m'The car is very fast.'\u001b[0m,\n",
       "    \u001b[32m'output'\u001b[0m: \u001b[32m'The car is as fast as lightning.'\u001b[0m,\n",
       "    \u001b[32m'model_response'\u001b[0m: \u001b[32m'The car is very fast.'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c499e8",
   "metadata": {},
   "source": [
    "#### 7.3 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb73b86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454e5719",
   "metadata": {},
   "source": [
    "### 8. 使用 llama 评估微调后的大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "482c9279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is very fast.\n",
      "\n",
      "Score:\n",
      ">> To rewrite the sentence using a simile, we can replace \"very\" with \"as\" and add \"like\" or \"as\" to make it a comparison.\n",
      "\n",
      "Corrected response: The car is as fast as lightning.\n",
      "\n",
      "Score: 100 (The model response was correct and provided a perfect example of how to rewrite the sentence using a simile.)\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is typically a thunderstorm with a high wind speed.\n",
      "\n",
      "Score:\n",
      ">> Score: 20\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* The model's response does not directly answer the question about the type of cloud associated with thunderstorms.\n",
      "* It mentions \"thunderstorm\" which is related to the topic but it's not a specific type of cloud.\n",
      "* It also includes irrelevant information like \"high wind speed\", which is not relevant to the question.\n",
      "\n",
      "A better response would be: \"The type of cloud typically associated with thunderstorms is cumulonimbus.\" This response directly answers the question and provides accurate information.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Sir Thomas More.\n",
      "\n",
      "Score:\n",
      ">> ### Model Response:\n",
      "The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "### Score: 0/100\n",
      "The model response is incorrect because Sir Thomas More was an English lawyer, statesman, and philosopher who lived in the 16th century, while Jane Austen was a novelist who wrote 'Pride and Prejudice' in the late 18th and early 19th centuries. The correct answer is Jane Austen.\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from llama import query_model\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78c78ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3.2\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            # print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc8546c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [00:25<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 91 of 110\n",
      "Average score: 48.62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
